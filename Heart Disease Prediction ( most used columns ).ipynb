{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e13e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33bdc201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  cp  thalach  oldpeak  ca  thal  target\n",
      "0   52   0      168      1.0   2     3       0\n",
      "1   53   0      155      3.1   0     3       0\n",
      "2   70   0      125      2.6   0     3       0\n",
      "3   61   0      161      0.0   1     3       0\n",
      "4   62   0      106      1.9   3     2       0\n",
      "(1025, 7)\n",
      "1    526\n",
      "0    499\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "readdata=pd.read_csv(r\"C:\\Users\\adhit\\ML Data sets\\Inhouse project\\heartv1.csv\")\n",
    "data = pd.DataFrame(readdata)\n",
    "#data = data.drop([87,166,192,266,287,302],axis=0)\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6db978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cp</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age           cp      thalach      oldpeak           ca  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean     54.434146     0.942439   149.114146     1.071512     0.754146   \n",
       "std       9.072290     1.029641    23.005724     1.175053     1.030798   \n",
       "min      29.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%      48.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%      56.000000     1.000000   152.000000     0.800000     0.000000   \n",
       "75%      61.000000     2.000000   166.000000     1.800000     1.000000   \n",
       "max      77.000000     3.000000   202.000000     6.200000     4.000000   \n",
       "\n",
       "              thal       target  \n",
       "count  1025.000000  1025.000000  \n",
       "mean      2.323902     0.513171  \n",
       "std       0.620660     0.500070  \n",
       "min       0.000000     0.000000  \n",
       "25%       2.000000     0.000000  \n",
       "50%       2.000000     1.000000  \n",
       "75%       3.000000     1.000000  \n",
       "max       3.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b280abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 7)\n",
      "(1025, 6)\n",
      "(1025, 1)\n",
      "      target\n",
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "...      ...\n",
      "1020       1\n",
      "1021       0\n",
      "1022       0\n",
      "1023       1\n",
      "1024       0\n",
      "\n",
      "[1025 rows x 1 columns]\n",
      "(717, 6) (308, 6) (717, 1) (308, 1)\n",
      "age         54.334728\n",
      "cp           0.921897\n",
      "thalach    149.377964\n",
      "oldpeak      1.071967\n",
      "ca           0.754533\n",
      "thal         2.327755\n",
      "dtype: float64 age         54.665584\n",
      "cp           0.990260\n",
      "thalach    148.500000\n",
      "oldpeak      1.070455\n",
      "ca           0.753247\n",
      "thal         2.314935\n",
      "dtype: float64 age         54.434146\n",
      "cp           0.942439\n",
      "thalach    149.114146\n",
      "oldpeak      1.071512\n",
      "ca           0.754146\n",
      "thal         2.323902\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "newdata=data.dropna(axis=0,how='any')\n",
    "print(newdata.shape)\n",
    "X = data.drop('target', axis=1)\n",
    "Y = data['target']\n",
    "Y1=list(Y)\n",
    "#Y = list(map(lambda x: 1 if x>0 else 0,Y1))\n",
    "#newx=pd.DataFrame(data.ix[:,[0,1,2,4,5,8,9,10,11]])\n",
    "#newx=data[data.columns[6]]\n",
    "#print(newx)\n",
    "#X = newx\n",
    "Y=pd.DataFrame(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Y)\n",
    "type(X)\n",
    "type(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify = Y, random_state=1)\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n",
    "print(X_train.mean(), X_test.mean(), X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "628d4f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.81818181818183\n",
      "89.24050632911393\n",
      "78.33333333333333\n",
      "0.8343195266272189\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "Fold 1 accuracy: 0.8446601941747572\n",
      "Fold 1 precision: 0.84\n",
      "Fold 1 recall: 0.84\n",
      "Fold 1 f1: 0.8399999999999999\n",
      "Mean Accuracy: 0.8446601941747572\n",
      "Mean Precision: 0.84\n",
      "Mean Recall: 0.84\n",
      "Mean F1: 0.8399999999999999\n",
      "Fold 2 accuracy: 0.9223300970873787\n",
      "Fold 2 precision: 0.8983050847457628\n",
      "Fold 2 recall: 0.9636363636363636\n",
      "Fold 2 f1: 0.9298245614035089\n",
      "Mean Accuracy: 0.883495145631068\n",
      "Mean Precision: 0.8691525423728814\n",
      "Mean Recall: 0.9018181818181819\n",
      "Mean F1: 0.8849122807017544\n",
      "Fold 3 accuracy: 0.8932038834951457\n",
      "Fold 3 precision: 0.9016393442622951\n",
      "Fold 3 recall: 0.9166666666666666\n",
      "Fold 3 f1: 0.9090909090909091\n",
      "Mean Accuracy: 0.8867313915857605\n",
      "Mean Precision: 0.8799814763360193\n",
      "Mean Recall: 0.9067676767676768\n",
      "Mean F1: 0.8929718234981393\n",
      "Fold 4 accuracy: 0.8349514563106796\n",
      "Fold 4 precision: 0.8461538461538461\n",
      "Fold 4 recall: 0.8301886792452831\n",
      "Fold 4 f1: 0.8380952380952382\n",
      "Mean Accuracy: 0.8737864077669903\n",
      "Mean Precision: 0.871524568790476\n",
      "Mean Recall: 0.8876229273870784\n",
      "Mean F1: 0.8792526771474141\n",
      "Fold 5 accuracy: 0.7961165048543689\n",
      "Fold 5 precision: 0.7868852459016393\n",
      "Fold 5 recall: 0.8571428571428571\n",
      "Fold 5 f1: 0.8205128205128205\n",
      "Mean Accuracy: 0.858252427184466\n",
      "Mean Precision: 0.8545967042127087\n",
      "Mean Recall: 0.8815269133382341\n",
      "Mean F1: 0.8675047058204953\n",
      "Fold 6 accuracy: 0.8823529411764706\n",
      "Fold 6 precision: 0.8958333333333334\n",
      "Fold 6 recall: 0.86\n",
      "Fold 6 f1: 0.8775510204081632\n",
      "Mean Accuracy: 0.8622691795164666\n",
      "Mean Precision: 0.8614694757328127\n",
      "Mean Recall: 0.8779390944485285\n",
      "Mean F1: 0.8691790915851066\n",
      "Fold 7 accuracy: 0.696078431372549\n",
      "Fold 7 precision: 0.6956521739130435\n",
      "Fold 7 recall: 0.6530612244897959\n",
      "Fold 7 f1: 0.6736842105263158\n",
      "Mean Accuracy: 0.8385276440673356\n",
      "Mean Precision: 0.8377812897585599\n",
      "Mean Recall: 0.8458136844544237\n",
      "Mean F1: 0.8412512514338509\n",
      "Fold 8 accuracy: 0.8137254901960784\n",
      "Fold 8 precision: 0.8571428571428571\n",
      "Fold 8 recall: 0.7777777777777778\n",
      "Fold 8 f1: 0.8155339805825242\n",
      "Mean Accuracy: 0.8354273748334285\n",
      "Mean Precision: 0.8402014856815971\n",
      "Mean Recall: 0.837309196119843\n",
      "Mean F1: 0.838036592577435\n",
      "Fold 9 accuracy: 0.7647058823529411\n",
      "Fold 9 precision: 0.7\n",
      "Fold 9 recall: 0.7954545454545454\n",
      "Fold 9 f1: 0.7446808510638298\n",
      "Mean Accuracy: 0.8275694312244855\n",
      "Mean Precision: 0.8246235428280864\n",
      "Mean Recall: 0.8326586793792544\n",
      "Mean F1: 0.8276637324092566\n",
      "Fold 10 accuracy: 0.7156862745098039\n",
      "Fold 10 precision: 0.7708333333333334\n",
      "Fold 10 recall: 0.6727272727272727\n",
      "Fold 10 f1: 0.7184466019417476\n",
      "Mean Accuracy: 0.8163811155530173\n",
      "Mean Precision: 0.8192445218786111\n",
      "Mean Recall: 0.8166655387140562\n",
      "Mean F1: 0.8167420193625057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lcclassifier = LogisticRegression()  \n",
    "lcclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = lcclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=lcclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=lcclassifier,algorithm=\"SAMME\",n_estimators=300)\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(boostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02134793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.23376623376623\n",
      "84.81012658227847\n",
      "97.8102189781022\n",
      "0.9084745762711864\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "K Fold Validation\n",
      "Fold 1 accuracy: 1.0\n",
      "Fold 1 precision: 1.0\n",
      "Fold 1 recall: 1.0\n",
      "Fold 1 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 2 accuracy: 0.9805825242718447\n",
      "Fold 2 precision: 0.9649122807017544\n",
      "Fold 2 recall: 1.0\n",
      "Fold 2 f1: 0.9821428571428572\n",
      "Mean Accuracy: 0.9902912621359223\n",
      "Mean Precision: 0.9824561403508771\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.9910714285714286\n",
      "Fold 3 accuracy: 0.9805825242718447\n",
      "Fold 3 precision: 1.0\n",
      "Fold 3 recall: 0.9666666666666667\n",
      "Fold 3 f1: 0.983050847457627\n",
      "Mean Accuracy: 0.9870550161812298\n",
      "Mean Precision: 0.9883040935672515\n",
      "Mean Recall: 0.9888888888888889\n",
      "Mean F1: 0.9883979015334948\n",
      "Fold 4 accuracy: 0.970873786407767\n",
      "Fold 4 precision: 1.0\n",
      "Fold 4 recall: 0.9433962264150944\n",
      "Fold 4 f1: 0.970873786407767\n",
      "Mean Accuracy: 0.9830097087378641\n",
      "Mean Precision: 0.9912280701754386\n",
      "Mean Recall: 0.9775157232704403\n",
      "Mean F1: 0.9840168727520628\n",
      "Fold 5 accuracy: 0.9029126213592233\n",
      "Fold 5 precision: 0.9107142857142857\n",
      "Fold 5 recall: 0.9107142857142857\n",
      "Fold 5 f1: 0.9107142857142857\n",
      "Mean Accuracy: 0.966990291262136\n",
      "Mean Precision: 0.975125313283208\n",
      "Mean Recall: 0.9641554357592094\n",
      "Mean F1: 0.9693563553445074\n",
      "Fold 6 accuracy: 0.9411764705882353\n",
      "Fold 6 precision: 0.9583333333333334\n",
      "Fold 6 recall: 0.92\n",
      "Fold 6 f1: 0.9387755102040817\n",
      "Mean Accuracy: 0.9626879878164859\n",
      "Mean Precision: 0.9723266499582288\n",
      "Mean Recall: 0.9567961964660078\n",
      "Mean F1: 0.964259547821103\n",
      "Fold 7 accuracy: 0.9803921568627451\n",
      "Fold 7 precision: 0.9607843137254902\n",
      "Fold 7 recall: 1.0\n",
      "Fold 7 f1: 0.98\n",
      "Mean Accuracy: 0.9652171548230944\n",
      "Mean Precision: 0.9706777447821233\n",
      "Mean Recall: 0.9629681683994352\n",
      "Mean F1: 0.9665081838466598\n",
      "Fold 8 accuracy: 0.9803921568627451\n",
      "Fold 8 precision: 0.9642857142857143\n",
      "Fold 8 recall: 1.0\n",
      "Fold 8 f1: 0.9818181818181818\n",
      "Mean Accuracy: 0.9671140300780506\n",
      "Mean Precision: 0.9698787409700722\n",
      "Mean Recall: 0.9675971473495057\n",
      "Mean F1: 0.9684219335931001\n",
      "Fold 9 accuracy: 0.9509803921568627\n",
      "Fold 9 precision: 0.9333333333333333\n",
      "Fold 9 recall: 0.9545454545454546\n",
      "Fold 9 f1: 0.9438202247191012\n",
      "Mean Accuracy: 0.965321403642363\n",
      "Mean Precision: 0.9658181401215457\n",
      "Mean Recall: 0.9661469592601668\n",
      "Mean F1: 0.965688410384878\n",
      "Fold 10 accuracy: 0.9607843137254902\n",
      "Fold 10 precision: 1.0\n",
      "Fold 10 recall: 0.9272727272727272\n",
      "Fold 10 f1: 0.9622641509433962\n",
      "Mean Accuracy: 0.9648676946506758\n",
      "Mean Precision: 0.9692363261093911\n",
      "Mean Recall: 0.9622595360614229\n",
      "Mean F1: 0.9653459844407297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "knnclassifier = KNeighborsClassifier(n_neighbors=2)  \n",
    "knnclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = knnclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=knnclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=knnclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "print(\"K Fold Validation\")\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "run_kfold(baggclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd35e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 81.16883116883116\n",
      "Precision= 89.24050632911393\n",
      "Recall= 77.47252747252747\n",
      "F1= 0.8294117647058824\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "K Fold Validation\n",
      "Fold 1 accuracy: 0.7961165048543689\n",
      "Fold 1 precision: 0.7457627118644068\n",
      "Fold 1 recall: 0.88\n",
      "Fold 1 f1: 0.8073394495412843\n",
      "Mean Accuracy: 0.7961165048543689\n",
      "Mean Precision: 0.7457627118644068\n",
      "Mean Recall: 0.88\n",
      "Mean F1: 0.8073394495412843\n",
      "Fold 2 accuracy: 0.9223300970873787\n",
      "Fold 2 precision: 0.8852459016393442\n",
      "Fold 2 recall: 0.9818181818181818\n",
      "Fold 2 f1: 0.9310344827586207\n",
      "Mean Accuracy: 0.8592233009708738\n",
      "Mean Precision: 0.8155043067518755\n",
      "Mean Recall: 0.9309090909090909\n",
      "Mean F1: 0.8691869661499525\n",
      "Fold 3 accuracy: 0.8737864077669902\n",
      "Fold 3 precision: 0.8852459016393442\n",
      "Fold 3 recall: 0.9\n",
      "Fold 3 f1: 0.8925619834710743\n",
      "Mean Accuracy: 0.8640776699029127\n",
      "Mean Precision: 0.8387515050476985\n",
      "Mean Recall: 0.9206060606060605\n",
      "Mean F1: 0.8769786385903263\n",
      "Fold 4 accuracy: 0.7281553398058253\n",
      "Fold 4 precision: 0.711864406779661\n",
      "Fold 4 recall: 0.7924528301886793\n",
      "Fold 4 f1: 0.75\n",
      "Mean Accuracy: 0.8300970873786409\n",
      "Mean Precision: 0.807029730480689\n",
      "Mean Recall: 0.8885677530017153\n",
      "Mean F1: 0.8452339789427448\n",
      "Fold 5 accuracy: 0.8058252427184466\n",
      "Fold 5 precision: 0.7571428571428571\n",
      "Fold 5 recall: 0.9464285714285714\n",
      "Fold 5 f1: 0.8412698412698413\n",
      "Mean Accuracy: 0.825242718446602\n",
      "Mean Precision: 0.7970523558131226\n",
      "Mean Recall: 0.9001399166870865\n",
      "Mean F1: 0.844441151408164\n",
      "Fold 6 accuracy: 0.8823529411764706\n",
      "Fold 6 precision: 0.8958333333333334\n",
      "Fold 6 recall: 0.86\n",
      "Fold 6 f1: 0.8775510204081632\n",
      "Mean Accuracy: 0.8347610889015801\n",
      "Mean Precision: 0.813515852066491\n",
      "Mean Recall: 0.8934499305725722\n",
      "Mean F1: 0.8499594629081639\n",
      "Fold 7 accuracy: 0.6568627450980392\n",
      "Fold 7 precision: 0.6206896551724138\n",
      "Fold 7 recall: 0.7346938775510204\n",
      "Fold 7 f1: 0.6728971962616822\n",
      "Mean Accuracy: 0.8093470397867886\n",
      "Mean Precision: 0.7859692525101943\n",
      "Mean Recall: 0.8707704944266361\n",
      "Mean F1: 0.8246648533872379\n",
      "Fold 8 accuracy: 0.7450980392156863\n",
      "Fold 8 precision: 0.75\n",
      "Fold 8 recall: 0.7777777777777778\n",
      "Fold 8 f1: 0.7636363636363638\n",
      "Mean Accuracy: 0.8013159147154008\n",
      "Mean Precision: 0.78147309594642\n",
      "Mean Recall: 0.8591464048455288\n",
      "Mean F1: 0.8170362921683787\n",
      "Fold 9 accuracy: 0.7450980392156863\n",
      "Fold 9 precision: 0.6730769230769231\n",
      "Fold 9 recall: 0.7954545454545454\n",
      "Fold 9 f1: 0.7291666666666666\n",
      "Mean Accuracy: 0.7950694841043213\n",
      "Mean Precision: 0.7694290767386982\n",
      "Mean Recall: 0.852069531579864\n",
      "Mean F1: 0.8072730004459663\n",
      "Fold 10 accuracy: 0.7549019607843137\n",
      "Fold 10 precision: 0.7586206896551724\n",
      "Fold 10 recall: 0.8\n",
      "Fold 10 f1: 0.7787610619469026\n",
      "Mean Accuracy: 0.7910527317723206\n",
      "Mean Precision: 0.7683482380303456\n",
      "Mean Recall: 0.8468625784218776\n",
      "Mean F1: 0.80442180659606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = svclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(\"Accuracy=\",accuracy*100)\n",
    "print(\"Precision=\",precision*100)\n",
    "print(\"Recall=\",recall*100)\n",
    "print(\"F1=\",f1)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=svclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=svclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "print(\"K Fold Validation\")\n",
    "def run_kfold(clf):\n",
    "    #kf = KFold(303, n_folds=10)\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "\n",
    "run_kfold(boostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ecc54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 72.07792207792207\n",
      "Precision= 74.68354430379746\n",
      "Recall= 71.95121951219512\n",
      "F1= 0.732919254658385\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "K Fold Validation\n",
      "Fold 1 accuracy: 0.4854368932038835\n",
      "Fold 1 precision: 0.4854368932038835\n",
      "Fold 1 recall: 1.0\n",
      "Fold 1 f1: 0.6535947712418301\n",
      "Mean Accuracy: 0.4854368932038835\n",
      "Mean Precision: 0.4854368932038835\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.6535947712418301\n",
      "Fold 2 accuracy: 0.5339805825242718\n",
      "Fold 2 precision: 0.5339805825242718\n",
      "Fold 2 recall: 1.0\n",
      "Fold 2 f1: 0.6962025316455696\n",
      "Mean Accuracy: 0.5097087378640777\n",
      "Mean Precision: 0.5097087378640777\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.6748986514436999\n",
      "Fold 3 accuracy: 0.5825242718446602\n",
      "Fold 3 precision: 0.5825242718446602\n",
      "Fold 3 recall: 1.0\n",
      "Fold 3 f1: 0.7361963190184049\n",
      "Mean Accuracy: 0.5339805825242718\n",
      "Mean Precision: 0.5339805825242718\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.6953312073019348\n",
      "Fold 4 accuracy: 0.5145631067961165\n",
      "Fold 4 precision: 0.5145631067961165\n",
      "Fold 4 recall: 1.0\n",
      "Fold 4 f1: 0.6794871794871795\n",
      "Mean Accuracy: 0.529126213592233\n",
      "Mean Precision: 0.529126213592233\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.691370200348246\n",
      "Fold 5 accuracy: 0.5436893203883495\n",
      "Fold 5 precision: 0.5436893203883495\n",
      "Fold 5 recall: 1.0\n",
      "Fold 5 f1: 0.7044025157232704\n",
      "Mean Accuracy: 0.5320388349514562\n",
      "Mean Precision: 0.5320388349514562\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.6939766634232509\n",
      "Fold 6 accuracy: 0.49019607843137253\n",
      "Fold 6 precision: 0.49019607843137253\n",
      "Fold 6 recall: 1.0\n",
      "Fold 6 f1: 0.6578947368421052\n",
      "Mean Accuracy: 0.525065042198109\n",
      "Mean Precision: 0.525065042198109\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.68796300899306\n",
      "Fold 7 accuracy: 0.4803921568627451\n",
      "Fold 7 precision: 0.4803921568627451\n",
      "Fold 7 recall: 1.0\n",
      "Fold 7 f1: 0.6490066225165563\n",
      "Mean Accuracy: 0.5186832014359142\n",
      "Mean Precision: 0.5186832014359142\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.6823978109249881\n",
      "Fold 8 accuracy: 0.5294117647058824\n",
      "Fold 8 precision: 0.5294117647058824\n",
      "Fold 8 recall: 1.0\n",
      "Fold 8 f1: 0.6923076923076924\n",
      "Mean Accuracy: 0.5200242718446602\n",
      "Mean Precision: 0.5200242718446602\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.683636546097826\n",
      "Fold 9 accuracy: 0.43137254901960786\n",
      "Fold 9 precision: 0.43137254901960786\n",
      "Fold 9 recall: 1.0\n",
      "Fold 9 f1: 0.6027397260273972\n",
      "Mean Accuracy: 0.5101740804196544\n",
      "Mean Precision: 0.5101740804196544\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.674648010534445\n",
      "Fold 10 accuracy: 0.5392156862745098\n",
      "Fold 10 precision: 0.5392156862745098\n",
      "Fold 10 recall: 1.0\n",
      "Fold 10 f1: 0.7006369426751593\n",
      "Mean Accuracy: 0.5130782410051399\n",
      "Mean Precision: 0.5130782410051399\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.6772469037485165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "svclassifier = SVC(kernel='rbf')  \n",
    "svclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = svclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(\"Accuracy=\",accuracy*100)\n",
    "print(\"Precision=\",precision*100)\n",
    "print(\"Recall=\",recall*100)\n",
    "print(\"F1=\",f1)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=svclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=svclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "print(\"K Fold Validation\")\n",
    "def run_kfold(clf):\n",
    "    #kf = KFold(303, n_folds=10)\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "\n",
    "run_kfold(boostclassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1188f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.06493506493507\n",
      "89.24050632911393\n",
      "82.94117647058825\n",
      "0.8597560975609756\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "Fold 1 accuracy: 0.8640776699029126\n",
      "Fold 1 precision: 0.86\n",
      "Fold 1 recall: 0.86\n",
      "Fold 1 f1: 0.8599999999999999\n",
      "Mean Accuracy: 0.8640776699029126\n",
      "Mean Precision: 0.86\n",
      "Mean Recall: 0.86\n",
      "Mean F1: 0.8599999999999999\n",
      "Fold 2 accuracy: 0.883495145631068\n",
      "Fold 2 precision: 0.8524590163934426\n",
      "Fold 2 recall: 0.9454545454545454\n",
      "Fold 2 f1: 0.8965517241379309\n",
      "Mean Accuracy: 0.8737864077669903\n",
      "Mean Precision: 0.8562295081967213\n",
      "Mean Recall: 0.9027272727272727\n",
      "Mean F1: 0.8782758620689655\n",
      "Fold 3 accuracy: 0.8932038834951457\n",
      "Fold 3 precision: 0.8769230769230769\n",
      "Fold 3 recall: 0.95\n",
      "Fold 3 f1: 0.912\n",
      "Mean Accuracy: 0.8802588996763755\n",
      "Mean Precision: 0.8631273644388399\n",
      "Mean Recall: 0.9184848484848485\n",
      "Mean F1: 0.8895172413793103\n",
      "Fold 4 accuracy: 0.7766990291262136\n",
      "Fold 4 precision: 0.7678571428571429\n",
      "Fold 4 recall: 0.8113207547169812\n",
      "Fold 4 f1: 0.7889908256880735\n",
      "Mean Accuracy: 0.854368932038835\n",
      "Mean Precision: 0.8393098090434156\n",
      "Mean Recall: 0.8916938250428816\n",
      "Mean F1: 0.8643856374565011\n",
      "Fold 5 accuracy: 0.8155339805825242\n",
      "Fold 5 precision: 0.8032786885245902\n",
      "Fold 5 recall: 0.875\n",
      "Fold 5 f1: 0.8376068376068376\n",
      "Mean Accuracy: 0.8466019417475728\n",
      "Mean Precision: 0.8321035849396505\n",
      "Mean Recall: 0.8883550600343053\n",
      "Mean F1: 0.8590298774865683\n",
      "Fold 6 accuracy: 0.8921568627450981\n",
      "Fold 6 precision: 0.8823529411764706\n",
      "Fold 6 recall: 0.9\n",
      "Fold 6 f1: 0.8910891089108911\n",
      "Mean Accuracy: 0.8541944285804938\n",
      "Mean Precision: 0.8404784776457873\n",
      "Mean Recall: 0.8902958833619211\n",
      "Mean F1: 0.8643730827239554\n",
      "Fold 7 accuracy: 0.7549019607843137\n",
      "Fold 7 precision: 0.7307692307692307\n",
      "Fold 7 recall: 0.7755102040816326\n",
      "Fold 7 f1: 0.7524752475247524\n",
      "Mean Accuracy: 0.8400097903238966\n",
      "Mean Precision: 0.8248057280919935\n",
      "Mean Recall: 0.8738979291790228\n",
      "Mean F1: 0.8483876776954978\n",
      "Fold 8 accuracy: 0.803921568627451\n",
      "Fold 8 precision: 0.8148148148148148\n",
      "Fold 8 recall: 0.8148148148148148\n",
      "Fold 8 f1: 0.8148148148148148\n",
      "Mean Accuracy: 0.8354987626118409\n",
      "Mean Precision: 0.8235568639323461\n",
      "Mean Recall: 0.8665125398834967\n",
      "Mean F1: 0.8441910698354125\n",
      "Fold 9 accuracy: 0.8431372549019608\n",
      "Fold 9 precision: 0.7692307692307693\n",
      "Fold 9 recall: 0.9090909090909091\n",
      "Fold 9 f1: 0.8333333333333333\n",
      "Mean Accuracy: 0.8363474839774097\n",
      "Mean Precision: 0.8175206311877264\n",
      "Mean Recall: 0.8712434697954314\n",
      "Mean F1: 0.8429846546685148\n",
      "Fold 10 accuracy: 0.8137254901960784\n",
      "Fold 10 precision: 0.8333333333333334\n",
      "Fold 10 recall: 0.8181818181818182\n",
      "Fold 10 f1: 0.8256880733944955\n",
      "Mean Accuracy: 0.8340852845992766\n",
      "Mean Precision: 0.8191019014022871\n",
      "Mean Recall: 0.86593730463407\n",
      "Mean F1: 0.8412549965411129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.cross_validation import KFold\n",
    "nbclassifier = GaussianNB()  \n",
    "nbclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = nbclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=nbclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=nbclassifier,algorithm=\"SAMME\",n_estimators=600)\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(boostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "398d2dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.76623376623377\n",
      "89.87341772151899\n",
      "80.68181818181817\n",
      "0.8502994011976047\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-74d92a23fc57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean F1: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_f1_outcome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[0mrun_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaggclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-74d92a23fc57>\u001b[0m in \u001b[0;36mrun_kfold\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_seeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         all_results = Parallel(n_jobs=n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    371\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             delayed(_parallel_build_estimators)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \"\"\"\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[0m\u001b[0;32m    405\u001b[0m                             intercept_grads, layer_units)\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[0miprint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[0;32m    491\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loss_grad_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L-BFGS-B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    617\u001b[0m                                   **options)\n\u001b[0;32m    618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    620\u001b[0m                                 callback=callback, **options)\n\u001b[0;32m    621\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[0m\u001b[0;32m    209\u001b[0m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0;32m    210\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# Iterate over the hidden layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m             \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m             \u001b[0minplace_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "nnclassifier = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(13,15,20,15,13), random_state=1, max_iter=200)\n",
    "nnclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = nnclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=nnclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=nnclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10, shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(baggclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e838258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.02597402597402\n",
      "98.10126582278481\n",
      "100.0\n",
      "0.9904153354632589\n",
      "Fold 1 accuracy: 1.0\n",
      "Fold 1 precision: 1.0\n",
      "Fold 1 recall: 1.0\n",
      "Fold 1 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 2 accuracy: 1.0\n",
      "Fold 2 precision: 1.0\n",
      "Fold 2 recall: 1.0\n",
      "Fold 2 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 3 accuracy: 1.0\n",
      "Fold 3 precision: 1.0\n",
      "Fold 3 recall: 1.0\n",
      "Fold 3 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 4 accuracy: 1.0\n",
      "Fold 4 precision: 1.0\n",
      "Fold 4 recall: 1.0\n",
      "Fold 4 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 5 accuracy: 1.0\n",
      "Fold 5 precision: 1.0\n",
      "Fold 5 recall: 1.0\n",
      "Fold 5 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 6 accuracy: 1.0\n",
      "Fold 6 precision: 1.0\n",
      "Fold 6 recall: 1.0\n",
      "Fold 6 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 7 accuracy: 0.9705882352941176\n",
      "Fold 7 precision: 1.0\n",
      "Fold 7 recall: 0.9387755102040817\n",
      "Fold 7 f1: 0.968421052631579\n",
      "Mean Accuracy: 0.9957983193277311\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 0.9912536443148687\n",
      "Mean F1: 0.9954887218045113\n",
      "Fold 8 accuracy: 1.0\n",
      "Fold 8 precision: 1.0\n",
      "Fold 8 recall: 1.0\n",
      "Fold 8 f1: 1.0\n",
      "Mean Accuracy: 0.9963235294117647\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 0.9923469387755102\n",
      "Mean F1: 0.9960526315789473\n",
      "Fold 9 accuracy: 0.9705882352941176\n",
      "Fold 9 precision: 0.9361702127659575\n",
      "Fold 9 recall: 1.0\n",
      "Fold 9 f1: 0.967032967032967\n",
      "Mean Accuracy: 0.9934640522875817\n",
      "Mean Precision: 0.9929078014184398\n",
      "Mean Recall: 0.9931972789115646\n",
      "Mean F1: 0.9928282244071718\n",
      "Fold 10 accuracy: 1.0\n",
      "Fold 10 precision: 1.0\n",
      "Fold 10 recall: 1.0\n",
      "Fold 10 f1: 1.0\n",
      "Mean Accuracy: 0.9941176470588236\n",
      "Mean Precision: 0.9936170212765958\n",
      "Mean Recall: 0.9938775510204081\n",
      "Mean F1: 0.9935454019664546\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#from sklearn.cross_validation import KFold\n",
    "xgclassifier = XGBClassifier(eval_metric='mlogloss')\n",
    "xgclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = xgclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(xgclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be792f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "Fold 1 accuracy: 1.0\n",
      "Fold 1 precision: 1.0\n",
      "Fold 1 recall: 1.0\n",
      "Fold 1 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 2 accuracy: 1.0\n",
      "Fold 2 precision: 1.0\n",
      "Fold 2 recall: 1.0\n",
      "Fold 2 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 3 accuracy: 1.0\n",
      "Fold 3 precision: 1.0\n",
      "Fold 3 recall: 1.0\n",
      "Fold 3 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 4 accuracy: 1.0\n",
      "Fold 4 precision: 1.0\n",
      "Fold 4 recall: 1.0\n",
      "Fold 4 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 5 accuracy: 1.0\n",
      "Fold 5 precision: 1.0\n",
      "Fold 5 recall: 1.0\n",
      "Fold 5 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 6 accuracy: 1.0\n",
      "Fold 6 precision: 1.0\n",
      "Fold 6 recall: 1.0\n",
      "Fold 6 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 7 accuracy: 1.0\n",
      "Fold 7 precision: 1.0\n",
      "Fold 7 recall: 1.0\n",
      "Fold 7 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 8 accuracy: 1.0\n",
      "Fold 8 precision: 1.0\n",
      "Fold 8 recall: 1.0\n",
      "Fold 8 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 9 accuracy: 0.9705882352941176\n",
      "Fold 9 precision: 0.9361702127659575\n",
      "Fold 9 recall: 1.0\n",
      "Fold 9 f1: 0.967032967032967\n",
      "Mean Accuracy: 0.9967320261437909\n",
      "Mean Precision: 0.9929078014184398\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.9963369963369964\n",
      "Fold 10 accuracy: 1.0\n",
      "Fold 10 precision: 1.0\n",
      "Fold 10 recall: 1.0\n",
      "Fold 10 f1: 1.0\n",
      "Mean Accuracy: 0.9970588235294118\n",
      "Mean Precision: 0.9936170212765958\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.9967032967032967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "dtclassifier = DecisionTreeClassifier()  \n",
    "dtclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = dtclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=dtclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=dtclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(boostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc54de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "Fold 1 accuracy: 1.0\n",
      "Fold 1 precision: 1.0\n",
      "Fold 1 recall: 1.0\n",
      "Fold 1 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 2 accuracy: 1.0\n",
      "Fold 2 precision: 1.0\n",
      "Fold 2 recall: 1.0\n",
      "Fold 2 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 3 accuracy: 1.0\n",
      "Fold 3 precision: 1.0\n",
      "Fold 3 recall: 1.0\n",
      "Fold 3 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 4 accuracy: 1.0\n",
      "Fold 4 precision: 1.0\n",
      "Fold 4 recall: 1.0\n",
      "Fold 4 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 5 accuracy: 1.0\n",
      "Fold 5 precision: 1.0\n",
      "Fold 5 recall: 1.0\n",
      "Fold 5 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 6 accuracy: 1.0\n",
      "Fold 6 precision: 1.0\n",
      "Fold 6 recall: 1.0\n",
      "Fold 6 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 7 accuracy: 1.0\n",
      "Fold 7 precision: 1.0\n",
      "Fold 7 recall: 1.0\n",
      "Fold 7 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 8 accuracy: 1.0\n",
      "Fold 8 precision: 1.0\n",
      "Fold 8 recall: 1.0\n",
      "Fold 8 f1: 1.0\n",
      "Mean Accuracy: 1.0\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 1.0\n",
      "Fold 9 accuracy: 0.9705882352941176\n",
      "Fold 9 precision: 0.9361702127659575\n",
      "Fold 9 recall: 1.0\n",
      "Fold 9 f1: 0.967032967032967\n",
      "Mean Accuracy: 0.9967320261437909\n",
      "Mean Precision: 0.9929078014184398\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.9963369963369964\n",
      "Fold 10 accuracy: 1.0\n",
      "Fold 10 precision: 1.0\n",
      "Fold 10 recall: 1.0\n",
      "Fold 10 f1: 1.0\n",
      "Mean Accuracy: 0.9970588235294118\n",
      "Mean Precision: 0.9936170212765958\n",
      "Mean Recall: 1.0\n",
      "Mean F1: 0.9967032967032967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "rfclassifier = RandomForestClassifier(n_estimators=100)  \n",
    "rfclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = rfclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=rfclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=rfclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(boostclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae9e1411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.15584415584416\n",
      "94.30379746835443\n",
      "94.30379746835443\n",
      "0.9430379746835443\n",
      "0.94\n",
      "0.056962025316455694\n",
      "Bagging Classifier\n",
      "Boosting Classifier\n",
      "Fold 1 accuracy: 0.970873786407767\n",
      "Fold 1 precision: 0.9607843137254902\n",
      "Fold 1 recall: 0.98\n",
      "Fold 1 f1: 0.9702970297029702\n",
      "Mean Accuracy: 0.970873786407767\n",
      "Mean Precision: 0.9607843137254902\n",
      "Mean Recall: 0.98\n",
      "Mean F1: 0.9702970297029702\n",
      "Fold 2 accuracy: 0.970873786407767\n",
      "Fold 2 precision: 0.9814814814814815\n",
      "Fold 2 recall: 0.9636363636363636\n",
      "Fold 2 f1: 0.9724770642201834\n",
      "Mean Accuracy: 0.970873786407767\n",
      "Mean Precision: 0.9711328976034859\n",
      "Mean Recall: 0.9718181818181818\n",
      "Mean F1: 0.9713870469615768\n",
      "Fold 3 accuracy: 0.9805825242718447\n",
      "Fold 3 precision: 0.9833333333333333\n",
      "Fold 3 recall: 0.9833333333333333\n",
      "Fold 3 f1: 0.9833333333333333\n",
      "Mean Accuracy: 0.9741100323624595\n",
      "Mean Precision: 0.975199709513435\n",
      "Mean Recall: 0.9756565656565656\n",
      "Mean F1: 0.975369142418829\n",
      "Fold 4 accuracy: 0.9320388349514563\n",
      "Fold 4 precision: 0.9791666666666666\n",
      "Fold 4 recall: 0.8867924528301887\n",
      "Fold 4 f1: 0.9306930693069307\n",
      "Mean Accuracy: 0.9635922330097088\n",
      "Mean Precision: 0.9761914488017429\n",
      "Mean Recall: 0.9534405374499714\n",
      "Mean F1: 0.9642001241408544\n",
      "Fold 5 accuracy: 0.9029126213592233\n",
      "Fold 5 precision: 0.8833333333333333\n",
      "Fold 5 recall: 0.9464285714285714\n",
      "Fold 5 f1: 0.9137931034482758\n",
      "Mean Accuracy: 0.9514563106796118\n",
      "Mean Precision: 0.9576198257080609\n",
      "Mean Recall: 0.9520381442456914\n",
      "Mean F1: 0.9541187200023387\n",
      "Fold 6 accuracy: 0.9803921568627451\n",
      "Fold 6 precision: 0.9615384615384616\n",
      "Fold 6 recall: 1.0\n",
      "Fold 6 f1: 0.9803921568627451\n",
      "Mean Accuracy: 0.956278951710134\n",
      "Mean Precision: 0.9582729316797943\n",
      "Mean Recall: 0.9600317868714096\n",
      "Mean F1: 0.9584976261457397\n",
      "Fold 7 accuracy: 0.9215686274509803\n",
      "Fold 7 precision: 0.9183673469387755\n",
      "Fold 7 recall: 0.9183673469387755\n",
      "Fold 7 f1: 0.9183673469387755\n",
      "Mean Accuracy: 0.9513203339588264\n",
      "Mean Precision: 0.9525721338596488\n",
      "Mean Recall: 0.9540797240238904\n",
      "Mean F1: 0.9527647291161735\n",
      "Fold 8 accuracy: 0.9313725490196079\n",
      "Fold 8 precision: 0.9122807017543859\n",
      "Fold 8 recall: 0.9629629629629629\n",
      "Fold 8 f1: 0.9369369369369369\n",
      "Mean Accuracy: 0.948826860841424\n",
      "Mean Precision: 0.947535704846491\n",
      "Mean Recall: 0.9551901288912745\n",
      "Mean F1: 0.9507862550937689\n",
      "Fold 9 accuracy: 0.9411764705882353\n",
      "Fold 9 precision: 0.8958333333333334\n",
      "Fold 9 recall: 0.9772727272727273\n",
      "Fold 9 f1: 0.9347826086956522\n",
      "Mean Accuracy: 0.9479768174799585\n",
      "Mean Precision: 0.9417909969005847\n",
      "Mean Recall: 0.9576437509336581\n",
      "Mean F1: 0.9490080721606449\n",
      "Fold 10 accuracy: 0.9411764705882353\n",
      "Fold 10 precision: 0.9622641509433962\n",
      "Fold 10 recall: 0.9272727272727272\n",
      "Fold 10 f1: 0.9444444444444444\n",
      "Mean Accuracy: 0.9472967827907862\n",
      "Mean Precision: 0.9438383123048657\n",
      "Mean Recall: 0.954606648567565\n",
      "Mean F1: 0.9485517093890248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "gbclassifier = GradientBoostingClassifier()  \n",
    "gbclassifier.fit(X_train, np.ravel(Y_train)) \n",
    "y_pred = gbclassifier.predict(X_test) \n",
    "accuracy=accuracy_score(y_pred,Y_test)\n",
    "precision=precision_score(y_pred,Y_test)\n",
    "recall=recall_score(y_pred,Y_test)\n",
    "f1=2*(precision*recall)/(precision+recall)\n",
    "cm=confusion_matrix(Y_test,y_pred)\n",
    "sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "print(accuracy*100)\n",
    "print(precision*100)\n",
    "print(recall*100)\n",
    "print(f1)\n",
    "print(sensitivity)\n",
    "print(specificity)\n",
    "print(\"Bagging Classifier\")\n",
    "baggclassifier=BaggingClassifier(base_estimator=gbclassifier,n_estimators=300)\n",
    "print(\"Boosting Classifier\")\n",
    "boostclassifier=AdaBoostClassifier(base_estimator=gbclassifier,algorithm=\"SAMME\",n_estimators=150)\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(10,shuffle=False)\n",
    "    outcomesaccuracy = []\n",
    "    outcomesprecision = []\n",
    "    outcomesrecall = []\n",
    "    outcomesf1 = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n",
    "        clf.fit(X_train, np.ravel(y_train))\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        precision=precision_score(y_test,predictions)\n",
    "        recall=recall_score(y_test,predictions)\n",
    "        f1=2*(precision*recall)/(precision+recall)\n",
    "        cm=confusion_matrix(Y_test,y_pred)\n",
    "        sensitivity=cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        specificity=cm[1,0]/(cm[1,0]+cm[1,1])\n",
    "        outcomesaccuracy.append(accuracy)\n",
    "        outcomesprecision.append(precision)\n",
    "        outcomesrecall.append(recall)\n",
    "        outcomesf1.append(f1)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy)) \n",
    "        print(\"Fold {0} precision: {1}\".format(fold, precision))\n",
    "        print(\"Fold {0} recall: {1}\".format(fold, recall))\n",
    "        print(\"Fold {0} f1: {1}\".format(fold, f1))\n",
    "        mean_accuracy_outcome = np.mean(outcomesaccuracy)\n",
    "        mean_precision_outcome = np.mean(outcomesprecision)\n",
    "        mean_recall_outcome = np.mean(outcomesrecall)\n",
    "        mean_f1_outcome = np.mean(outcomesf1)\n",
    "        print(\"Mean Accuracy: {0}\".format(mean_accuracy_outcome)) \n",
    "        print(\"Mean Precision: {0}\".format(mean_precision_outcome))\n",
    "        print(\"Mean Recall: {0}\".format(mean_recall_outcome))\n",
    "        print(\"Mean F1: {0}\".format(mean_f1_outcome))\n",
    "        \n",
    "run_kfold(baggclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96476abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
